import OpenAI from 'openai';
import { AccessToken } from 'livekit-server-sdk';
import { config } from './index';

// Configura√ß√£o do OpenAI
export const openaiClient = new OpenAI({
  apiKey: config.OPENAI_API_KEY,
  // S√≥ incluir organization se ela existir e n√£o estiver vazia
  ...(config.OPENAI_ORGANIZATION && config.OPENAI_ORGANIZATION.length > 0 && {
    organization: config.OPENAI_ORGANIZATION
  }),
  timeout: 30000, // 30 segundos
  maxRetries: 3,
});

// Teste de conex√£o com OpenAI
export async function testOpenAIConnection(): Promise<boolean> {
  try {
    const response = await openaiClient.models.list();
    
    if (response.data && response.data.length > 0) {
      console.log('‚úÖ Conex√£o com OpenAI estabelecida com sucesso');
      console.log(`   Modelos dispon√≠veis: ${response.data.length}`);
      return true;
    }
    
    console.error('‚ùå OpenAI conectado mas sem modelos dispon√≠veis');
    return false;
  } catch (error) {
    console.error('‚ùå Falha ao conectar com OpenAI:', error);
    return false;
  }
}

// Configura√ß√µes do LiveKit
export const livekitSettings = {
  url: config.LIVEKIT_URL,
  apiKey: config.LIVEKIT_API_KEY,
  apiSecret: config.LIVEKIT_API_SECRET,
};

// Gera√ß√£o de tokens LiveKit
export async function generateLiveKitToken(
  identity: string,
  roomName: string,
  options: {
    canPublish?: boolean;
    canSubscribe?: boolean;
    canPublishData?: boolean;
    metadata?: string;
  } = {}
): Promise<string> {
  const {
    canPublish = true,
    canSubscribe = true,
    canPublishData = true,
    metadata,
  } = options;

  const at = new AccessToken(
    config.LIVEKIT_API_KEY,
    config.LIVEKIT_API_SECRET,
    { identity, metadata }
  );

  // TTL em segundos (24h)
  at.ttl = 24 * 60 * 60;

  at.addGrant({
    room: roomName,
    roomJoin: true,
    canPublish,
    canSubscribe,
    canPublishData,
  });

  return await at.toJwt(); // <- agora aguardando a Promise
}

// Teste de configura√ß√£o do LiveKit
export async function testLiveKitConfig(): Promise<boolean> {
  try {
    const testToken = await generateLiveKitToken('test-user', 'test-room'); // <- await

    if (testToken && testToken.length > 0) {
      console.log('‚úÖ Configura√ß√£o do LiveKit v√°lida');
      console.log(`   URL: ${config.LIVEKIT_URL}`);
      return true;
    }

    console.error('‚ùå Falha ao gerar token LiveKit');
    return false;
  } catch (error) {
    console.error('‚ùå Configura√ß√£o inv√°lida do LiveKit:', error);
    return false;
  }
}

// Configura√ß√£o Redis (opcional por enquanto)
export const redisSettings = config.REDIS_URL 
  ? {
      url: config.REDIS_URL,
      password: config.REDIS_PASSWORD,
      retryDelayOnFailover: 100,
      maxRetriesPerRequest: 3,
      lazyConnect: true,
    }
  : null;

// Teste de conex√£o Redis (se configurado)
export async function testRedisConnection(): Promise<boolean> {
  if (!redisSettings) {
    console.log('‚ö†Ô∏è  Redis n√£o configurado - usando modo sem cache');
    return true; // N√£o √© erro, apenas n√£o est√° configurado
  }

  try {
    // TODO: Implementar teste de conex√£o Redis quando necess√°rio
    console.log('‚ö†Ô∏è  Redis configurado mas teste n√£o implementado ainda');
    return true;
  } catch (error) {
    console.error('‚ùå Falha ao conectar com Redis:', error);
    return false;
  }
}

// Configura√ß√µes de AI espec√≠ficas para diferentes modelos
export const aiModels = {
  transcription: {
    openai: {
      model: 'whisper-1',
      language: 'pt',
      response_format: 'verbose_json' as const,
      temperature: 0,
    },
    // Placeholder para outros providers
    google: {
      model: 'latest_long',
      languageCode: 'pt-BR',
      enableAutomaticPunctuation: true,
      useEnhanced: true,
    },
  },
  
  completion: {
    model: config.LLM_MODEL,
    temperature: config.LLM_TEMPERATURE,
    max_tokens: config.LLM_MAX_TOKENS,
    top_p: 1,
    frequency_penalty: 0,
    presence_penalty: 0,
  },

  embedding: {
    model: 'text-embedding-3-small',
    dimensions: 1536,
  },
};

// Helper para criar chat completion
export async function makeChatCompletion(
  messages: OpenAI.Chat.ChatCompletionMessageParam[],
  options: Partial<OpenAI.Chat.ChatCompletionCreateParams> = {}
) {
  const params: OpenAI.Chat.ChatCompletionCreateParams = {
    ...aiModels.completion,
    messages,
    ...options,
  };

  return await openaiClient.chat.completions.create(params);
}

// Helper para criar embeddings
export async function makeEmbedding(text: string) {
  return await openaiClient.embeddings.create({
    model: aiModels.embedding.model,
    input: text,
    dimensions: aiModels.embedding.dimensions,
  });
}

// Valida√ß√£o de todas as configura√ß√µes
export async function validateAllProviders(): Promise<{
  openai: boolean;
  livekit: boolean;
  redis: boolean;
}> {
  console.log('üîÑ Validando conex√µes com provedores...\n');

  const results = {
    openai: await testOpenAIConnection(),
    livekit: await testLiveKitConfig(),
    redis: await testRedisConnection(),
  };

  console.log('\nüìä Resultado da valida√ß√£o:');
  console.log(`   OpenAI: ${results.openai ? '‚úÖ' : '‚ùå'}`);
  console.log(`   LiveKit: ${results.livekit ? '‚úÖ' : '‚ùå'}`);
  console.log(`   Redis: ${results.redis ? '‚úÖ' : '‚ö†Ô∏è'}`);

  return results;
}