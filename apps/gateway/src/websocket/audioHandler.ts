import { Socket } from 'socket.io';
import { audioProcessor, AudioChunk } from '@/services/audioProcessor';
import { asrService } from '@/services/asrService';
import { SessionNotifier } from './index';

const isDevelopment = process.env.NODE_ENV === 'development';

export interface PresentialAudioData {
  sessionId: string;
  audioData: number[]; // Array serializado do Float32Array
  timestamp: number;
  sampleRate: number;
}

export interface PresentialSessionData {
  sessionId: string;
  consultationId: string;
  timestamp: string;
}

export function setupPresentialAudioHandlers(socket: Socket, notifier: SessionNotifier): void {
  
  // Handler para √°udio do m√©dico
  socket.on('presential:audio:doctor', (data: PresentialAudioData) => {
    try {
      const { sessionId, audioData, timestamp, sampleRate } = data;
      
      if (!sessionId || !audioData || !Array.isArray(audioData)) {
        socket.emit('error', {
          code: 'INVALID_AUDIO_DATA',
          message: 'Dados de √°udio inv√°lidos para m√©dico'
        });
        return;
      }

      // Converter array de volta para Float32Array
      const float32AudioData = new Float32Array(audioData);

      // Criar chunk de √°udio
      const audioChunk: AudioChunk = {
        sessionId,
        channel: 'doctor',
        audioData: float32AudioData,
        timestamp,
        sampleRate
      };

      // Processar √°udio
      audioProcessor.processAudioChunk(audioChunk);

      if (isDevelopment) {
        //console.log(`üé§ √Åudio m√©dico recebido: ${audioData.length} samples - Sess√£o: ${sessionId}`);
      }
      
    } catch (error) {
      console.error('Erro ao processar √°udio do m√©dico:', error);
      socket.emit('session:error', {
        sessionId: data.sessionId,
        error: {
          code: 'AUDIO_PROCESSING_ERROR',
          message: 'Erro ao processar √°udio do m√©dico'
        }
      });
    }
  });

  // Handler para √°udio do paciente
  socket.on('presential:audio:patient', (data: PresentialAudioData) => {
    try {
      const { sessionId, audioData, timestamp, sampleRate } = data;
      
      if (!sessionId || !audioData || !Array.isArray(audioData)) {
        socket.emit('error', {
          code: 'INVALID_AUDIO_DATA',
          message: 'Dados de √°udio inv√°lidos para paciente'
        });
        return;
      }

      // Converter array de volta para Float32Array
      const float32AudioData = new Float32Array(audioData);

      // Criar chunk de √°udio
      const audioChunk: AudioChunk = {
        sessionId,
        channel: 'patient',
        audioData: float32AudioData,
        timestamp,
        sampleRate
      };

      // Processar √°udio
      audioProcessor.processAudioChunk(audioChunk);

      if (isDevelopment) {
        //console.log(`üé§ √Åudio paciente recebido: ${audioData.length} samples - Sess√£o: ${sessionId}`);
      }
      
    } catch (error) {
      console.error('Erro ao processar √°udio do paciente:', error);
      socket.emit('session:error', {
        sessionId: data.sessionId,
        error: {
          code: 'AUDIO_PROCESSING_ERROR',
          message: 'Erro ao processar √°udio do paciente'
        }
      });
    }
  });

  // Handler para iniciar grava√ß√£o presencial
  socket.on('presential:start_recording', (data: PresentialSessionData) => {
    try {
      const { sessionId, consultationId } = data;
      
      if (!sessionId) {
        socket.emit('error', {
          code: 'INVALID_SESSION_ID',
          message: 'ID da sess√£o √© obrigat√≥rio'
        });
        return;
      }

      // Configurar listeners do processador de √°udio para esta sess√£o
      setupAudioProcessorListeners(sessionId, notifier);

      // Notificar outros participantes que a grava√ß√£o iniciou
      notifier.emitProcessingStatus(sessionId, 'processing', 'Grava√ß√£o iniciada');
      
      // Confirmar in√≠cio da grava√ß√£o
      socket.emit('presential:recording_started', {
        sessionId,
        timestamp: new Date().toISOString()
      });

    } catch (error) {
      console.error('Erro ao iniciar grava√ß√£o presencial:', error);
      socket.emit('session:error', {
        sessionId: data.sessionId,
        error: {
          code: 'START_RECORDING_ERROR',
          message: 'Erro ao iniciar grava√ß√£o presencial'
        }
      });
    }
  });

  // Handler para parar grava√ß√£o presencial
  socket.on('presential:stop_recording', (data: { sessionId: string; timestamp: string }) => {
    try {
      const { sessionId } = data;
      
      if (!sessionId) {
        socket.emit('error', {
          code: 'INVALID_SESSION_ID',
          message: 'ID da sess√£o √© obrigat√≥rio'
        });
        return;
      }

      // PRIORIT√ÅRIO: Processar frases pendentes primeiro
      audioProcessor.flushPendingPhrases(sessionId);
      
      // CR√çTICO: Remover listeners para evitar vazamentos
      const listenersToRemove = activeListeners.get(sessionId);
      if (listenersToRemove) {
        globalListenerCount--;
        audioProcessor.off('audio:processed', listenersToRemove.onAudioProcessed);
        audioProcessor.off('audio:voice_activity', listenersToRemove.onVoiceActivity);
        audioProcessor.off('audio:silence', listenersToRemove.onSilence);
        activeListeners.delete(sessionId);
      }
      
      // DESABILITADO: N√£o processar buffers restantes no modo frases completas
      // audioProcessor.flushPendingBuffers(sessionId);

      // Limpar buffers da sess√£o
      audioProcessor.clearSession(sessionId);

      // Notificar fim da grava√ß√£o
      notifier.emitProcessingStatus(sessionId, 'completed', 'Grava√ß√£o finalizada');
      
      // Confirmar fim da grava√ß√£o
      socket.emit('presential:recording_stopped', {
        sessionId,
        timestamp: new Date().toISOString()
      });

    } catch (error) {
      console.error('Erro ao parar grava√ß√£o presencial:', error);
      socket.emit('session:error', {
        sessionId: data.sessionId,
        error: {
          code: 'STOP_RECORDING_ERROR',
          message: 'Erro ao finalizar grava√ß√£o presencial'
        }
      });
    }
  });

  // Handler para obter estat√≠sticas de √°udio
  socket.on('presential:audio_stats', (data: { sessionId: string }) => {
    try {
      const stats = audioProcessor.getStats();
      
      socket.emit('presential:audio_stats_response', {
        sessionId: data.sessionId,
        stats,
        timestamp: new Date().toISOString()
      });

    } catch (error) {
      console.error('Erro ao obter estat√≠sticas de √°udio:', error);
      socket.emit('error', {
        code: 'AUDIO_STATS_ERROR',
        message: 'Erro ao obter estat√≠sticas de √°udio'
      });
    }
  });
}

// Map para controlar listeners ativos por sess√£o
const activeListeners = new Map<string, {
  onAudioProcessed: (processedChunk: any) => void;
  onVoiceActivity: (data: any) => void;
  onSilence: (data: any) => void;
}>();

// üîç DEBUG: Contador global de listeners
let globalListenerCount = 0;

// üõ°Ô∏è PROTE√á√ÉO CONTRA RACE CONDITIONS: Set de IDs enviados recentemente
const sentTranscriptionIds = new Set<string>();


// Configurar listeners do processador de √°udio para uma sess√£o
function setupAudioProcessorListeners(sessionId: string, notifier: SessionNotifier): void {
  
  // CR√çTICO: Remover listeners anteriores se existirem
  const existingListeners = activeListeners.get(sessionId);
  if (existingListeners) {
    globalListenerCount--;
    audioProcessor.off('audio:processed', existingListeners.onAudioProcessed);
    audioProcessor.off('audio:voice_activity', existingListeners.onVoiceActivity);
    audioProcessor.off('audio:silence', existingListeners.onSilence);
  }
  
  // Listener para √°udio processado
  const onAudioProcessed = (processedChunk: any) => {
    if (processedChunk.sessionId === sessionId) {
      // üîç DEBUG [AUDIO_PROCESSING]: Come√ßou processar √°udio
      console.log(`üîç DEBUG [AUDIO_PROCESSING] ${processedChunk.channel} - ${Math.round(processedChunk.duration)}ms`);
      
      // üîç DEBUG [TRANSCRIPTION_SEND]: Enviado para transcri√ß√£o
      console.log(`üîç DEBUG [TRANSCRIPTION_SEND] ${processedChunk.channel} ‚Üí Whisper`);
      
      // Enviar para ASR
      asrService.processAudio(processedChunk)
        .then((transcription) => {
          if (transcription) {
            // üîç DEBUG [TRANSCRIPTION_RECEIVED]: Transcri√ß√£o recebida
            console.log(`üîç DEBUG [TRANSCRIPTION_RECEIVED] ${transcription.speaker}: "${transcription.text}"`);

            // Formatar transcri√ß√£o para o frontend
            const utterance = {
              id: transcription.id,
              speaker: transcription.speaker,
              text: transcription.text,
              timestamp: transcription.timestamp,
              confidence: transcription.confidence
            };
            
            // üõ°Ô∏è PROTE√á√ÉO CONTRA RACE CONDITION: Verificar se ID j√° foi enviado
            if (sentTranscriptionIds.has(transcription.id)) {
              return;
            }
            
            // Marcar como enviado ANTES de enviar (evita race condition)
            sentTranscriptionIds.add(transcription.id);
            
            // üîç DEBUG [WEBSOCKET_SEND]: Enviado para WebSocket
            console.log(`üîç DEBUG [WEBSOCKET_SEND] ${transcription.speaker} ‚Üí Frontend`);
            
            // Emitir transcri√ß√£o via WebSocket
            notifier.emitTranscriptionUpdate(sessionId, utterance);
            
            // Limpeza peri√≥dica do Set (manter √∫ltimos 1000 IDs)
            if (sentTranscriptionIds.size > 1000) {
              const idsArray = Array.from(sentTranscriptionIds);
              sentTranscriptionIds.clear();
              // Manter s√≥ os √∫ltimos 500 IDs
              idsArray.slice(-500).forEach(id => sentTranscriptionIds.add(id));
            }
          }
        })
        .catch((error) => {
          console.error(`üîç DEBUG [TRANSCRIPTION_ERROR]:`, error);
          notifier.emitSessionError(sessionId, {
            code: 'TRANSCRIPTION_ERROR',
            message: 'Erro no processamento de transcri√ß√£o'
          });
        });
    }
  };

  // Listener para atividade de voz
  const onVoiceActivity = (data: any) => {
    if (data.sessionId === sessionId) {
      // üîç DEBUG [VOICE_START/END]: Log in√≠cio/fim da fala
      if (data.isActive) {
        console.log(`üîç DEBUG [VOICE_START] ${data.channel} come√ßou a falar`);
      } else {
        console.log(`üîç DEBUG [VOICE_END] ${data.channel} terminou de falar`);
      }
      
      // Emitir evento de atividade de voz
      notifier.emitVoiceActivity(sessionId, data.channel, data.isActive);
    }
  };

  // Listener para sil√™ncio
  const onSilence = (data: any) => {
    // Removido - log desnecess√°rio para o tunnel
  };

  // Registrar listeners
  globalListenerCount++;
  audioProcessor.on('audio:processed', onAudioProcessed);
  audioProcessor.on('audio:voice_activity', onVoiceActivity);
  audioProcessor.on('audio:silence', onSilence);

  // CR√çTICO: Armazenar refer√™ncias dos listeners para remo√ß√£o futura
  activeListeners.set(sessionId, {
    onAudioProcessed,
    onVoiceActivity,
    onSilence
  });
}
